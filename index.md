# <center>Hierarchical Diffusion Models for Singing Voice Neural Vocoder</center>

<center><a href="https://scholar.google.com/citations?user=JbtYJMoAAAAJ">Naoya Takahashi</a>, Mayank Kumar Singh, Yuki Mitsufuji</center><br> 
<center>Sony Group Coporation</center> 

<br>

## Introduction
Despite progress in neural vocoders, generating a high-quality singing voice remains challenging due to a wider variety of musical expressions in pitch, loudness, and pronunciations. In this work, we propose a hierarchical diffusion model for singing voice neural vocoders. The proposed method consists of multiple diffusion models operating in different sampling rates; the model at the lowest sampling rate focuses on generating accurate low-frequency components such as pitch, and other models progressively generate the waveform at higher sampling rates on the basis of the data at the lower sampling rate and acoustic features. In this demo page, we present some audio samples.
